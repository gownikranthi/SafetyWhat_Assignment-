{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76701b4e-08ee-4c78-9aed-7e8cba366803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl (45.5 MB)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c218de50-8db9-496e-9a15-69f03a0e04eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to your video file\n",
    "video_path = r\"C:\\Users\\Lenovo\\Desktop\\SaftyWhatAssessment\\WhatsApp Video 2025-01-10 at 19.49.01_bc3eb6d9.mp4\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video loaded successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    print(\"Video loaded successfully!\")\n",
    "\n",
    "# Release video capture after testing\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29c9a3a-7e94-4a3b-af6d-2015d3d5e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3618108a-8f04-4089-abb1-58c99fc79569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Display the frame using Matplotlib\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')  # Remove axis for better visualization\n",
    "    plt.show()\n",
    "    \n",
    "    # Break after displaying a single frame\n",
    "    break\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36872b3-de60-4e67-8cf6-8bd6d80765d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Using cached ultralytics-8.3.59-py3-none-any.whl (906 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: torch, ultralytics-thop, torchvision, ultralytics\n",
      "Successfully installed torch-2.5.1 torchvision-0.20.1 ultralytics-8.3.59 ultralytics-thop-2.0.13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts ultralytics.exe and yolo.exe are installed in 'C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafaaff0-14f8-4c4e-94a3-714b8fafc79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 3 persons, 2 dogs, 1 chair, 168.2ms\n",
      "Speed: 1.4ms preprocess, 168.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 222.4ms\n",
      "Speed: 0.0ms preprocess, 222.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 skateboard, 1 chair, 182.3ms\n",
      "Speed: 0.8ms preprocess, 182.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 184.7ms\n",
      "Speed: 0.0ms preprocess, 184.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 116.3ms\n",
      "Speed: 0.0ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 118.0ms\n",
      "Speed: 0.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 137.3ms\n",
      "Speed: 0.0ms preprocess, 137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 117.6ms\n",
      "Speed: 3.0ms preprocess, 117.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 135.9ms\n",
      "Speed: 3.0ms preprocess, 135.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 120.4ms\n",
      "Speed: 3.4ms preprocess, 120.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 137.2ms\n",
      "Speed: 2.1ms preprocess, 137.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 97.8ms\n",
      "Speed: 0.0ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 100.5ms\n",
      "Speed: 3.6ms preprocess, 100.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 112.0ms\n",
      "Speed: 0.0ms preprocess, 112.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 118.6ms\n",
      "Speed: 3.0ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 98.1ms\n",
      "Speed: 0.0ms preprocess, 98.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 90.2ms\n",
      "Speed: 3.0ms preprocess, 90.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 96.4ms\n",
      "Speed: 3.4ms preprocess, 96.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 113.3ms\n",
      "Speed: 6.4ms preprocess, 113.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 104.5ms\n",
      "Speed: 3.0ms preprocess, 104.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 97.0ms\n",
      "Speed: 0.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 114.0ms\n",
      "Speed: 0.0ms preprocess, 114.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 113.1ms\n",
      "Speed: 0.0ms preprocess, 113.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 176.0ms\n",
      "Speed: 5.0ms preprocess, 176.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 143.3ms\n",
      "Speed: 4.7ms preprocess, 143.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 178.9ms\n",
      "Speed: 7.9ms preprocess, 178.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 132.3ms\n",
      "Speed: 3.0ms preprocess, 132.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 130.7ms\n",
      "Speed: 3.0ms preprocess, 130.7ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 131.0ms\n",
      "Speed: 0.0ms preprocess, 131.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 98.3ms\n",
      "Speed: 3.8ms preprocess, 98.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 114.1ms\n",
      "Speed: 0.0ms preprocess, 114.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 131.1ms\n",
      "Speed: 0.0ms preprocess, 131.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 150.5ms\n",
      "Speed: 0.0ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 150.4ms\n",
      "Speed: 0.0ms preprocess, 150.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 119.0ms\n",
      "Speed: 0.0ms preprocess, 119.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 116.5ms\n",
      "Speed: 0.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 101.2ms\n",
      "Speed: 3.0ms preprocess, 101.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 101.8ms\n",
      "Speed: 3.0ms preprocess, 101.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 3 potted plants, 99.6ms\n",
      "Speed: 3.0ms preprocess, 99.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 2 potted plants, 100.6ms\n",
      "Speed: 3.0ms preprocess, 100.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 98.5ms\n",
      "Speed: 3.8ms preprocess, 98.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 1 potted plant, 106.2ms\n",
      "Speed: 16.3ms preprocess, 106.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 2 chairs, 1 potted plant, 128.5ms\n",
      "Speed: 3.5ms preprocess, 128.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 153.4ms\n",
      "Speed: 0.0ms preprocess, 153.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 224.3ms\n",
      "Speed: 0.0ms preprocess, 224.3ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 175.9ms\n",
      "Speed: 18.5ms preprocess, 175.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 89.3ms\n",
      "Speed: 3.0ms preprocess, 89.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 82.4ms\n",
      "Speed: 3.0ms preprocess, 82.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 1 potted plant, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 1 bowl, 1 chair, 1 potted plant, 99.6ms\n",
      "Speed: 4.0ms preprocess, 99.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 chair, 103.6ms\n",
      "Speed: 3.0ms preprocess, 103.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 chair, 1 potted plant, 103.2ms\n",
      "Speed: 3.0ms preprocess, 103.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 potted plant, 113.7ms\n",
      "Speed: 18.8ms preprocess, 113.7ms inference, 16.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 165.9ms\n",
      "Speed: 0.0ms preprocess, 165.9ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 115.0ms\n",
      "Speed: 0.0ms preprocess, 115.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 92.2ms\n",
      "Speed: 3.0ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 102.7ms\n",
      "Speed: 3.0ms preprocess, 102.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 bowls, 1 potted plant, 110.2ms\n",
      "Speed: 0.8ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 96.2ms\n",
      "Speed: 4.0ms preprocess, 96.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 bowls, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 125.1ms\n",
      "Speed: 0.0ms preprocess, 125.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 132.7ms\n",
      "Speed: 0.0ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 148.5ms\n",
      "Speed: 0.0ms preprocess, 148.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 150.0ms\n",
      "Speed: 0.0ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 166.0ms\n",
      "Speed: 0.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 3 bowls, 167.6ms\n",
      "Speed: 0.0ms preprocess, 167.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 3 bowls, 226.2ms\n",
      "Speed: 0.0ms preprocess, 226.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 1 cup, 150.4ms\n",
      "Speed: 0.0ms preprocess, 150.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 124.8ms\n",
      "Speed: 0.0ms preprocess, 124.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 bowl, 2 potted plants, 97.1ms\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 141.5ms\n",
      "Speed: 3.0ms preprocess, 141.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 potted plants, 106.0ms\n",
      "Speed: 17.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 handbag, 1 potted plant, 112.6ms\n",
      "Speed: 3.0ms preprocess, 112.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 117.4ms\n",
      "Speed: 0.0ms preprocess, 117.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 101.9ms\n",
      "Speed: 4.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 95.4ms\n",
      "Speed: 3.7ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 100.5ms\n",
      "Speed: 3.0ms preprocess, 100.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bird, 1 dog, 1 bowl, 2 potted plants, 105.1ms\n",
      "Speed: 2.0ms preprocess, 105.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 114.4ms\n",
      "Speed: 0.0ms preprocess, 114.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 119.3ms\n",
      "Speed: 0.0ms preprocess, 119.3ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 177.1ms\n",
      "Speed: 0.0ms preprocess, 177.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 124.7ms\n",
      "Speed: 5.1ms preprocess, 124.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 199.4ms\n",
      "Speed: 0.0ms preprocess, 199.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 148.3ms\n",
      "Speed: 3.0ms preprocess, 148.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 111.0ms\n",
      "Speed: 2.5ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 105.7ms\n",
      "Speed: 2.0ms preprocess, 105.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 94.3ms\n",
      "Speed: 2.0ms preprocess, 94.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 102.4ms\n",
      "Speed: 2.0ms preprocess, 102.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 114.6ms\n",
      "Speed: 3.0ms preprocess, 114.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 110.5ms\n",
      "Speed: 3.0ms preprocess, 110.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 106.2ms\n",
      "Speed: 4.0ms preprocess, 106.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 110.6ms\n",
      "Speed: 3.0ms preprocess, 110.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 4 potted plants, 106.7ms\n",
      "Speed: 3.0ms preprocess, 106.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 99.4ms\n",
      "Speed: 3.0ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 93.8ms\n",
      "Speed: 2.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 90.9ms\n",
      "Speed: 3.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 94.4ms\n",
      "Speed: 2.5ms preprocess, 94.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 85.2ms\n",
      "Speed: 3.0ms preprocess, 85.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 86.6ms\n",
      "Speed: 3.0ms preprocess, 86.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 95.2ms\n",
      "Speed: 3.6ms preprocess, 95.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 145.3ms\n",
      "Speed: 0.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 107.3ms\n",
      "Speed: 3.0ms preprocess, 107.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 157.5ms\n",
      "Speed: 3.5ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 117.6ms\n",
      "Speed: 3.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 101.8ms\n",
      "Speed: 3.0ms preprocess, 101.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 2 bowls, 87.8ms\n",
      "Speed: 3.0ms preprocess, 87.8ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 bowl, 84.3ms\n",
      "Speed: 3.0ms preprocess, 84.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 handbag, 3 potted plants, 92.8ms\n",
      "Speed: 2.0ms preprocess, 92.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 92.5ms\n",
      "Speed: 2.0ms preprocess, 92.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 78.5ms\n",
      "Speed: 3.0ms preprocess, 78.5ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 84.5ms\n",
      "Speed: 3.0ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 99.4ms\n",
      "Speed: 2.5ms preprocess, 99.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 94.6ms\n",
      "Speed: 3.0ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 85.7ms\n",
      "Speed: 4.0ms preprocess, 85.7ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 88.6ms\n",
      "Speed: 3.0ms preprocess, 88.6ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 3 potted plants, 132.5ms\n",
      "Speed: 3.0ms preprocess, 132.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 97.8ms\n",
      "Speed: 4.0ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 98.1ms\n",
      "Speed: 4.4ms preprocess, 98.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 3 potted plants, 123.8ms\n",
      "Speed: 6.8ms preprocess, 123.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 96.8ms\n",
      "Speed: 4.8ms preprocess, 96.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 3 potted plants, 149.2ms\n",
      "Speed: 3.0ms preprocess, 149.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 126.9ms\n",
      "Speed: 5.5ms preprocess, 126.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 82.4ms\n",
      "Speed: 4.0ms preprocess, 82.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 99.4ms\n",
      "Speed: 2.5ms preprocess, 99.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 88.1ms\n",
      "Speed: 3.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 potted plants, 82.1ms\n",
      "Speed: 2.1ms preprocess, 82.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 87.8ms\n",
      "Speed: 3.0ms preprocess, 87.8ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 3 potted plants, 91.2ms\n",
      "Speed: 3.0ms preprocess, 91.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 94.0ms\n",
      "Speed: 3.7ms preprocess, 94.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 118.8ms\n",
      "Speed: 3.0ms preprocess, 118.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 101.4ms\n",
      "Speed: 3.0ms preprocess, 101.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 93.3ms\n",
      "Speed: 2.7ms preprocess, 93.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 106.9ms\n",
      "Speed: 3.0ms preprocess, 106.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 96.7ms\n",
      "Speed: 3.0ms preprocess, 96.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 101.7ms\n",
      "Speed: 3.0ms preprocess, 101.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 121.8ms\n",
      "Speed: 3.0ms preprocess, 121.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 111.5ms\n",
      "Speed: 4.4ms preprocess, 111.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 potted plant, 127.0ms\n",
      "Speed: 2.0ms preprocess, 127.0ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 138.0ms\n",
      "Speed: 4.0ms preprocess, 138.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 129.2ms\n",
      "Speed: 3.0ms preprocess, 129.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 90.9ms\n",
      "Speed: 2.0ms preprocess, 90.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 105.8ms\n",
      "Speed: 2.0ms preprocess, 105.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 94.0ms\n",
      "Speed: 4.6ms preprocess, 94.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 3 potted plants, 115.0ms\n",
      "Speed: 0.0ms preprocess, 115.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bowl, 4 potted plants, 122.7ms\n",
      "Speed: 3.5ms preprocess, 122.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 95.5ms\n",
      "Speed: 3.0ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 87.7ms\n",
      "Speed: 3.0ms preprocess, 87.7ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 potted plant, 86.1ms\n",
      "Speed: 3.0ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 potted plant, 129.6ms\n",
      "Speed: 3.0ms preprocess, 129.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 107.6ms\n",
      "Speed: 3.5ms preprocess, 107.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 92.4ms\n",
      "Speed: 3.0ms preprocess, 92.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 potted plant, 90.8ms\n",
      "Speed: 2.5ms preprocess, 90.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 potted plant, 84.1ms\n",
      "Speed: 3.0ms preprocess, 84.1ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 112.1ms\n",
      "Speed: 8.3ms preprocess, 112.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 107.8ms\n",
      "Speed: 14.3ms preprocess, 107.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 105.3ms\n",
      "Speed: 3.0ms preprocess, 105.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 136.9ms\n",
      "Speed: 4.0ms preprocess, 136.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 113.1ms\n",
      "Speed: 0.0ms preprocess, 113.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 162.4ms\n",
      "Speed: 3.0ms preprocess, 162.4ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 132.8ms\n",
      "Speed: 3.0ms preprocess, 132.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 93.0ms\n",
      "Speed: 12.4ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 87.1ms\n",
      "Speed: 3.0ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 91.8ms\n",
      "Speed: 3.0ms preprocess, 91.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 87.1ms\n",
      "Speed: 3.0ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 89.2ms\n",
      "Speed: 3.0ms preprocess, 89.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 92.8ms\n",
      "Speed: 4.1ms preprocess, 92.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 98.9ms\n",
      "Speed: 14.4ms preprocess, 98.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 90.4ms\n",
      "Speed: 3.0ms preprocess, 90.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 93.7ms\n",
      "Speed: 16.2ms preprocess, 93.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 84.9ms\n",
      "Speed: 3.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bowl, 104.7ms\n",
      "Speed: 3.0ms preprocess, 104.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 potted plant, 91.7ms\n",
      "Speed: 3.0ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 potted plant, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 134.1ms\n",
      "Speed: 3.0ms preprocess, 134.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 potted plant, 98.1ms\n",
      "Speed: 0.0ms preprocess, 98.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 potted plant, 141.9ms\n",
      "Speed: 3.0ms preprocess, 141.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 2 potted plants, 141.6ms\n",
      "Speed: 18.7ms preprocess, 141.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 90.1ms\n",
      "Speed: 4.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 114.3ms\n",
      "Speed: 3.1ms preprocess, 114.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 106.7ms\n",
      "Speed: 3.0ms preprocess, 106.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 99.0ms\n",
      "Speed: 12.2ms preprocess, 99.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 114.3ms\n",
      "Speed: 11.1ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 2 chairs, 115.4ms\n",
      "Speed: 17.3ms preprocess, 115.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 chairs, 115.1ms\n",
      "Speed: 0.0ms preprocess, 115.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 chairs, 100.6ms\n",
      "Speed: 14.8ms preprocess, 100.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 115.8ms\n",
      "Speed: 0.0ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 1 potted plant, 98.2ms\n",
      "Speed: 17.1ms preprocess, 98.2ms inference, 16.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 chair, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 2 chairs, 149.6ms\n",
      "Speed: 0.0ms preprocess, 149.6ms inference, 15.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 2 chairs, 183.0ms\n",
      "Speed: 0.0ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 221.6ms\n",
      "Speed: 0.0ms preprocess, 221.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 174.4ms\n",
      "Speed: 0.0ms preprocess, 174.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 2 chairs, 163.5ms\n",
      "Speed: 0.0ms preprocess, 163.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 105.7ms\n",
      "Speed: 3.0ms preprocess, 105.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 107.1ms\n",
      "Speed: 3.1ms preprocess, 107.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# End of video\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Run YOLO detection\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Visualize detections on the frame\u001b[39;00m\n\u001b[0;32m     32\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:180\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    153\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    154\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:558\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:173\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:524\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 524\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:55\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Path to your video file\n",
    "video_path = r\"C:\\Users\\Lenovo\\Desktop\\SaftyWhatAssessment\\WhatsApp Video 2025-01-10 at 19.49.01_bc3eb6d9.mp4\"\n",
    "output_dir = \"output_frames\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # End of video\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Visualize detections on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Save the annotated frame\n",
    "    frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "    cv2.imwrite(frame_path, annotated_frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # Display the frame (optional)\n",
    "    cv2.imshow(\"YOLO Detection\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Annotated frames saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0550211b-19ce-481b-a1a4-c39f12ceef28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m: [x1, y1, x2, y2],\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubobject\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflower_pot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m: [x1, y1, x2, y2]\n\u001b[0;32m      9\u001b[0m   }\n\u001b[0;32m     10\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    "  \"object\": \"person\",\n",
    "  \"id\": 1,\n",
    "  \"bbox\": [x1, y1, x2, y2],\n",
    "  \"subobject\": {\n",
    "    \"object\": \"flower_pot\",\n",
    "    \"id\": 1,\n",
    "    \"bbox\": [x1, y1, x2, y2]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2119f55-6ff6-4282-a6f5-2c64877b4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 3 persons, 2 dogs, 1 chair, 71.6ms\n",
      "Speed: 4.1ms preprocess, 71.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 78.3ms\n",
      "Speed: 0.0ms preprocess, 78.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 skateboard, 1 chair, 75.3ms\n",
      "Speed: 2.1ms preprocess, 75.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 88.1ms\n",
      "Speed: 2.0ms preprocess, 88.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 87.3ms\n",
      "Speed: 3.1ms preprocess, 87.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 85.3ms\n",
      "Speed: 2.3ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 97.4ms\n",
      "Speed: 3.8ms preprocess, 97.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 75.3ms\n",
      "Speed: 3.4ms preprocess, 75.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 83.7ms\n",
      "Speed: 3.1ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 93.4ms\n",
      "Speed: 3.1ms preprocess, 93.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 100.9ms\n",
      "Speed: 4.0ms preprocess, 100.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 98.4ms\n",
      "Speed: 18.2ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 90.7ms\n",
      "Speed: 0.0ms preprocess, 90.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 94.8ms\n",
      "Speed: 3.0ms preprocess, 94.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 96.7ms\n",
      "Speed: 4.0ms preprocess, 96.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 79.7ms\n",
      "Speed: 3.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 97.5ms\n",
      "Speed: 3.0ms preprocess, 97.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 76.7ms\n",
      "Speed: 2.0ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 82.7ms\n",
      "Speed: 17.3ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 113.0ms\n",
      "Speed: 2.0ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 79.8ms\n",
      "Speed: 3.9ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 94.9ms\n",
      "Speed: 3.3ms preprocess, 94.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 89.5ms\n",
      "Speed: 2.1ms preprocess, 89.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 93.8ms\n",
      "Speed: 2.0ms preprocess, 93.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 96.3ms\n",
      "Speed: 3.5ms preprocess, 96.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 97.3ms\n",
      "Speed: 3.7ms preprocess, 97.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 92.9ms\n",
      "Speed: 3.7ms preprocess, 92.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 92.9ms\n",
      "Speed: 2.9ms preprocess, 92.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 76.7ms\n",
      "Speed: 3.6ms preprocess, 76.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 1 chair, 3 potted plants, 77.8ms\n",
      "Speed: 3.0ms preprocess, 77.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 2 potted plants, 77.8ms\n",
      "Speed: 2.0ms preprocess, 77.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 1 potted plant, 109.6ms\n",
      "Speed: 3.3ms preprocess, 109.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 78.7ms\n",
      "Speed: 2.8ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 2 chairs, 1 potted plant, 77.0ms\n",
      "Speed: 3.2ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 75.7ms\n",
      "Speed: 3.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 83.2ms\n",
      "Speed: 2.8ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 84.2ms\n",
      "Speed: 3.0ms preprocess, 84.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 90.9ms\n",
      "Speed: 3.4ms preprocess, 90.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 1 potted plant, 96.4ms\n",
      "Speed: 4.0ms preprocess, 96.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 1 bowl, 1 chair, 1 potted plant, 94.8ms\n",
      "Speed: 3.2ms preprocess, 94.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 chair, 99.5ms\n",
      "Speed: 0.0ms preprocess, 99.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 chair, 1 potted plant, 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 2 bowls, 1 potted plant, 89.3ms\n",
      "Speed: 3.5ms preprocess, 89.3ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 100.2ms\n",
      "Speed: 0.0ms preprocess, 100.2ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 99.2ms\n",
      "Speed: 0.0ms preprocess, 99.2ms inference, 16.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 101.5ms\n",
      "Speed: 15.0ms preprocess, 101.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 85.1ms\n",
      "Speed: 15.2ms preprocess, 85.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 bowls, 1 potted plant, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 80.8ms\n",
      "Speed: 4.0ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 bowls, 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 83.5ms\n",
      "Speed: 0.0ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 83.4ms\n",
      "Speed: 0.0ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 128.7ms\n",
      "Speed: 0.0ms preprocess, 128.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 85.6ms\n",
      "Speed: 3.0ms preprocess, 85.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 87.5ms\n",
      "Speed: 3.0ms preprocess, 87.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 3 bowls, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 3 bowls, 89.7ms\n",
      "Speed: 3.0ms preprocess, 89.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 1 cup, 86.4ms\n",
      "Speed: 3.8ms preprocess, 86.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 dog, 99.9ms\n",
      "Speed: 3.1ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 cat, 1 bowl, 2 potted plants, 97.3ms\n",
      "Speed: 3.4ms preprocess, 97.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 121.6ms\n",
      "Speed: 2.0ms preprocess, 121.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 118.6ms\n",
      "Speed: 4.0ms preprocess, 118.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 potted plants, 91.9ms\n",
      "Speed: 3.0ms preprocess, 91.9ms inference, 16.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 handbag, 1 potted plant, 104.1ms\n",
      "Speed: 3.0ms preprocess, 104.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 95.7ms\n",
      "Speed: 3.0ms preprocess, 95.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 97.2ms\n",
      "Speed: 0.0ms preprocess, 97.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 86.7ms\n",
      "Speed: 3.0ms preprocess, 86.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 87.7ms\n",
      "Speed: 2.0ms preprocess, 87.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 85.9ms\n",
      "Speed: 2.0ms preprocess, 85.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 81.8ms\n",
      "Speed: 3.0ms preprocess, 81.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bird, 1 dog, 1 bowl, 2 potted plants, 82.5ms\n",
      "Speed: 3.0ms preprocess, 82.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 82.4ms\n",
      "Speed: 2.0ms preprocess, 82.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 80.1ms\n",
      "Speed: 3.0ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 114.8ms\n",
      "Speed: 2.0ms preprocess, 114.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 82.4ms\n",
      "Speed: 2.0ms preprocess, 82.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 83.9ms\n",
      "Speed: 2.7ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 92.6ms\n",
      "Speed: 3.6ms preprocess, 92.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 89.3ms\n",
      "Speed: 3.0ms preprocess, 89.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 89.8ms\n",
      "Speed: 3.0ms preprocess, 89.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 103.9ms\n",
      "Speed: 3.3ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 96.4ms\n",
      "Speed: 3.0ms preprocess, 96.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 93.5ms\n",
      "Speed: 3.4ms preprocess, 93.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 potted plants, 106.1ms\n",
      "Speed: 3.0ms preprocess, 106.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 potted plant, 81.5ms\n",
      "Speed: 2.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 4 potted plants, 83.2ms\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 78.7ms\n",
      "Speed: 2.0ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 80.5ms\n",
      "Speed: 3.0ms preprocess, 80.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 75.2ms\n",
      "Speed: 2.0ms preprocess, 75.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 78.1ms\n",
      "Speed: 3.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 99.6ms\n",
      "Speed: 0.0ms preprocess, 99.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 89.0ms\n",
      "Speed: 15.8ms preprocess, 89.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 125.5ms\n",
      "Speed: 3.0ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 81.9ms\n",
      "Speed: 2.8ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 113.0ms\n",
      "Speed: 3.0ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 2 bowls, 95.8ms\n",
      "Speed: 3.7ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 bowl, 100.9ms\n",
      "Speed: 2.0ms preprocess, 100.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 handbag, 3 potted plants, 98.1ms\n",
      "Speed: 3.0ms preprocess, 98.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 94.2ms\n",
      "Speed: 3.0ms preprocess, 94.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 92.5ms\n",
      "Speed: 3.7ms preprocess, 92.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 96.7ms\n",
      "Speed: 3.0ms preprocess, 96.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 82.3ms\n",
      "Speed: 3.9ms preprocess, 82.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 100.4ms\n",
      "Speed: 0.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 86.3ms\n",
      "Speed: 3.0ms preprocess, 86.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 82.2ms\n",
      "Speed: 2.0ms preprocess, 82.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 3 potted plants, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 132.9ms\n",
      "Speed: 0.0ms preprocess, 132.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 86.4ms\n",
      "Speed: 4.0ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 3 potted plants, 82.7ms\n",
      "Speed: 3.3ms preprocess, 82.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 86.1ms\n",
      "Speed: 3.0ms preprocess, 86.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 3 potted plants, 86.6ms\n",
      "Speed: 3.0ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 94.0ms\n",
      "Speed: 0.0ms preprocess, 94.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 97.5ms\n",
      "Speed: 2.0ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 92.3ms\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 potted plants, 88.7ms\n",
      "Speed: 3.7ms preprocess, 88.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 3 potted plants, 92.2ms\n",
      "Speed: 3.0ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 97.5ms\n",
      "Speed: 2.5ms preprocess, 97.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 94.3ms\n",
      "Speed: 4.2ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 88.3ms\n",
      "Speed: 3.0ms preprocess, 88.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 82.8ms\n",
      "Speed: 0.0ms preprocess, 82.8ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 83.4ms\n",
      "Speed: 16.5ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 78.7ms\n",
      "Speed: 4.5ms preprocess, 78.7ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 potted plant, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 102.0ms\n",
      "Speed: 0.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 86.5ms\n",
      "Speed: 3.6ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 82.7ms\n",
      "Speed: 2.5ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 84.1ms\n",
      "Speed: 16.4ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 113.2ms\n",
      "Speed: 0.0ms preprocess, 113.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 3 potted plants, 99.7ms\n",
      "Speed: 3.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bowl, 4 potted plants, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 136.1ms\n",
      "Speed: 3.0ms preprocess, 136.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 potted plant, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 potted plant, 80.3ms\n",
      "Speed: 3.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 99.8ms\n",
      "Speed: 0.0ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 potted plant, 83.3ms\n",
      "Speed: 0.0ms preprocess, 83.3ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 potted plant, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 83.3ms\n",
      "Speed: 1.3ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 97.7ms\n",
      "Speed: 0.0ms preprocess, 97.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 80.8ms\n",
      "Speed: 3.0ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 82.9ms\n",
      "Speed: 9.4ms preprocess, 82.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 132.9ms\n",
      "Speed: 0.0ms preprocess, 132.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 118.7ms\n",
      "Speed: 0.0ms preprocess, 118.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 110.0ms\n",
      "Speed: 3.0ms preprocess, 110.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 117.3ms\n",
      "Speed: 3.4ms preprocess, 117.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 128.6ms\n",
      "Speed: 14.9ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 75.9ms\n",
      "Speed: 3.0ms preprocess, 75.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 100.9ms\n",
      "Speed: 0.0ms preprocess, 100.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 83.3ms\n",
      "Speed: 0.0ms preprocess, 83.3ms inference, 16.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 99.7ms\n",
      "Speed: 0.0ms preprocess, 99.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 99.7ms\n",
      "Speed: 0.0ms preprocess, 99.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 bowls, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bowl, 83.5ms\n",
      "Speed: 0.0ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 potted plant, 83.2ms\n",
      "Speed: 0.0ms preprocess, 83.2ms inference, 16.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 potted plant, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 99.8ms\n",
      "Speed: 0.0ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 potted plant, 85.7ms\n",
      "Speed: 3.0ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 potted plant, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 2 potted plants, 96.4ms\n",
      "Speed: 17.8ms preprocess, 96.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 104.1ms\n",
      "Speed: 3.0ms preprocess, 104.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 97.0ms\n",
      "Speed: 3.4ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 105.8ms\n",
      "Speed: 3.0ms preprocess, 105.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 140.2ms\n",
      "Speed: 2.0ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 97.1ms\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 100.0ms\n",
      "Speed: 2.5ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 2 chairs, 99.9ms\n",
      "Speed: 2.0ms preprocess, 99.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 chairs, 103.9ms\n",
      "Speed: 3.0ms preprocess, 103.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 2 chairs, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 80.8ms\n",
      "Speed: 3.0ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 1 potted plant, 83.3ms\n",
      "Speed: 3.0ms preprocess, 83.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 1 chair, 83.8ms\n",
      "Speed: 3.0ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 dog, 1 bowl, 2 chairs, 86.8ms\n",
      "Speed: 2.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 2 chairs, 111.9ms\n",
      "Speed: 3.0ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 85.1ms\n",
      "Speed: 3.0ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 1 chair, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 bowl, 2 chairs, 93.3ms\n",
      "Speed: 3.0ms preprocess, 93.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 84.8ms\n",
      "Speed: 3.0ms preprocess, 84.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 95.6ms\n",
      "Speed: 3.0ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 bowl, 97.9ms\n",
      "Speed: 17.8ms preprocess, 97.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 134.4ms\n",
      "Speed: 3.5ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 bowl, 1 chair, 100.8ms\n",
      "Speed: 4.0ms preprocess, 100.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 105.9ms\n",
      "Speed: 3.0ms preprocess, 105.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 106.3ms\n",
      "Speed: 3.0ms preprocess, 106.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 104.6ms\n",
      "Speed: 4.0ms preprocess, 104.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 93.1ms\n",
      "Speed: 3.0ms preprocess, 93.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 93.7ms\n",
      "Speed: 3.0ms preprocess, 93.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 89.6ms\n",
      "Speed: 3.0ms preprocess, 89.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.1ms\n",
      "Speed: 3.0ms preprocess, 91.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 123.5ms\n",
      "Speed: 2.0ms preprocess, 123.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 95.1ms\n",
      "Speed: 4.8ms preprocess, 95.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 skateboard, 1 bowl, 1 chair, 89.2ms\n",
      "Speed: 3.0ms preprocess, 89.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 skateboard, 2 bowls, 1 chair, 92.2ms\n",
      "Speed: 3.4ms preprocess, 92.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 suitcase, 1 bowl, 1 chair, 105.6ms\n",
      "Speed: 3.0ms preprocess, 105.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 108.4ms\n",
      "Speed: 15.0ms preprocess, 108.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 101.3ms\n",
      "Speed: 3.0ms preprocess, 101.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 99.7ms\n",
      "Speed: 3.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 102.4ms\n",
      "Speed: 3.0ms preprocess, 102.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 104.3ms\n",
      "Speed: 3.0ms preprocess, 104.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 88.6ms\n",
      "Speed: 3.0ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 88.7ms\n",
      "Speed: 3.0ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 74.2ms\n",
      "Speed: 3.0ms preprocess, 74.2ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 118.0ms\n",
      "Speed: 4.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 95.6ms\n",
      "Speed: 3.0ms preprocess, 95.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 95.4ms\n",
      "Speed: 3.5ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.9ms\n",
      "Speed: 3.0ms preprocess, 91.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 93.2ms\n",
      "Speed: 3.0ms preprocess, 93.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 93.3ms\n",
      "Speed: 3.0ms preprocess, 93.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 107.6ms\n",
      "Speed: 3.0ms preprocess, 107.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 146.5ms\n",
      "Speed: 4.1ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 111.8ms\n",
      "Speed: 3.0ms preprocess, 111.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 chairs, 111.1ms\n",
      "Speed: 3.0ms preprocess, 111.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 112.0ms\n",
      "Speed: 3.5ms preprocess, 112.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 109.7ms\n",
      "Speed: 6.0ms preprocess, 109.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 92.3ms\n",
      "Speed: 4.0ms preprocess, 92.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 89.8ms\n",
      "Speed: 2.0ms preprocess, 89.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.2ms\n",
      "Speed: 3.0ms preprocess, 91.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 121.6ms\n",
      "Speed: 3.0ms preprocess, 121.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 92.7ms\n",
      "Speed: 3.0ms preprocess, 92.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 2 chairs, 1 potted plant, 95.6ms\n",
      "Speed: 3.6ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 94.7ms\n",
      "Speed: 2.0ms preprocess, 94.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 89.6ms\n",
      "Speed: 3.0ms preprocess, 89.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 93.1ms\n",
      "Speed: 3.0ms preprocess, 93.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 153.0ms\n",
      "Speed: 3.0ms preprocess, 153.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 2 bowls, 1 chair, 115.5ms\n",
      "Speed: 4.0ms preprocess, 115.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 bowl, 1 chair, 120.3ms\n",
      "Speed: 0.0ms preprocess, 120.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 120.9ms\n",
      "Speed: 3.0ms preprocess, 120.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 106.5ms\n",
      "Speed: 2.6ms preprocess, 106.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 1 potted plant, 133.0ms\n",
      "Speed: 3.3ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 99.0ms\n",
      "Speed: 4.1ms preprocess, 99.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 117.2ms\n",
      "Speed: 4.0ms preprocess, 117.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 89.9ms\n",
      "Speed: 3.0ms preprocess, 89.9ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 102.8ms\n",
      "Speed: 3.0ms preprocess, 102.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 chairs, 1 potted plant, 87.3ms\n",
      "Speed: 3.2ms preprocess, 87.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 94.5ms\n",
      "Speed: 3.0ms preprocess, 94.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 91.2ms\n",
      "Speed: 3.0ms preprocess, 91.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 chairs, 94.7ms\n",
      "Speed: 4.0ms preprocess, 94.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 116.6ms\n",
      "Speed: 3.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 97.0ms\n",
      "Speed: 4.5ms preprocess, 97.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 100.3ms\n",
      "Speed: 4.0ms preprocess, 100.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 109.3ms\n",
      "Speed: 3.0ms preprocess, 109.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 chairs, 110.9ms\n",
      "Speed: 3.0ms preprocess, 110.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 110.8ms\n",
      "Speed: 4.0ms preprocess, 110.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 110.2ms\n",
      "Speed: 3.0ms preprocess, 110.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 151.6ms\n",
      "Speed: 3.0ms preprocess, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 103.3ms\n",
      "Speed: 4.2ms preprocess, 103.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 83.6ms\n",
      "Speed: 3.0ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 88.7ms\n",
      "Speed: 3.0ms preprocess, 88.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 115.4ms\n",
      "Speed: 0.0ms preprocess, 115.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 92.5ms\n",
      "Speed: 3.7ms preprocess, 92.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bench, 1 dog, 1 bowl, 1 chair, 87.9ms\n",
      "Speed: 3.0ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 bowls, 1 chair, 129.5ms\n",
      "Speed: 3.0ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 93.6ms\n",
      "Speed: 3.0ms preprocess, 93.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 16.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 123.1ms\n",
      "Speed: 0.0ms preprocess, 123.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 116.3ms\n",
      "Speed: 0.0ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 127.1ms\n",
      "Speed: 0.0ms preprocess, 127.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 166.2ms\n",
      "Speed: 0.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 133.3ms\n",
      "Speed: 0.0ms preprocess, 133.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 135.8ms\n",
      "Speed: 0.0ms preprocess, 135.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 98.4ms\n",
      "Speed: 1.5ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 99.5ms\n",
      "Speed: 0.0ms preprocess, 99.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 116.3ms\n",
      "Speed: 0.0ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 89.5ms\n",
      "Speed: 0.0ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 137.3ms\n",
      "Speed: 0.0ms preprocess, 137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 94.3ms\n",
      "Speed: 3.0ms preprocess, 94.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 110.5ms\n",
      "Speed: 0.0ms preprocess, 110.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 91.1ms\n",
      "Speed: 3.0ms preprocess, 91.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 92.3ms\n",
      "Speed: 3.5ms preprocess, 92.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 100.1ms\n",
      "Speed: 3.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 153.9ms\n",
      "Speed: 3.0ms preprocess, 153.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 120.5ms\n",
      "Speed: 3.0ms preprocess, 120.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 117.3ms\n",
      "Speed: 3.0ms preprocess, 117.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 121.3ms\n",
      "Speed: 3.0ms preprocess, 121.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 106.8ms\n",
      "Speed: 3.0ms preprocess, 106.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bench, 1 dog, 1 chair, 134.9ms\n",
      "Speed: 3.0ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 96.2ms\n",
      "Speed: 3.0ms preprocess, 96.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 93.8ms\n",
      "Speed: 9.5ms preprocess, 93.8ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 102.5ms\n",
      "Speed: 0.0ms preprocess, 102.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bench, 1 dog, 1 horse, 1 chair, 1 potted plant, 102.2ms\n",
      "Speed: 0.0ms preprocess, 102.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bench, 1 dog, 1 chair, 1 potted plant, 100.4ms\n",
      "Speed: 0.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 94.4ms\n",
      "Speed: 3.0ms preprocess, 94.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 89.2ms\n",
      "Speed: 10.3ms preprocess, 89.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 1 potted plant, 102.4ms\n",
      "Speed: 3.0ms preprocess, 102.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 117.7ms\n",
      "Speed: 3.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 120.3ms\n",
      "Speed: 3.0ms preprocess, 120.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 114.3ms\n",
      "Speed: 3.0ms preprocess, 114.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 117.3ms\n",
      "Speed: 4.0ms preprocess, 117.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 chair, 116.3ms\n",
      "Speed: 3.0ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 159.5ms\n",
      "Speed: 3.0ms preprocess, 159.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 114.8ms\n",
      "Speed: 3.1ms preprocess, 114.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 105.2ms\n",
      "Speed: 0.0ms preprocess, 105.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 101.4ms\n",
      "Speed: 3.0ms preprocess, 101.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 103.2ms\n",
      "Speed: 0.0ms preprocess, 103.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 dogs, 1 chair, 93.5ms\n",
      "Speed: 3.0ms preprocess, 93.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 101.9ms\n",
      "Speed: 0.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 170.0ms\n",
      "Speed: 0.0ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 99.5ms\n",
      "Speed: 16.6ms preprocess, 99.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 116.5ms\n",
      "Speed: 0.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 120.9ms\n",
      "Speed: 0.0ms preprocess, 120.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 149.4ms\n",
      "Speed: 0.0ms preprocess, 149.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 142.5ms\n",
      "Speed: 0.0ms preprocess, 142.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 dogs, 1 suitcase, 1 chair, 134.1ms\n",
      "Speed: 0.0ms preprocess, 134.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 2 potted plants, 144.4ms\n",
      "Speed: 3.0ms preprocess, 144.4ms inference, 15.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 120.4ms\n",
      "Speed: 15.0ms preprocess, 120.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 97.5ms\n",
      "Speed: 3.0ms preprocess, 97.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 104.2ms\n",
      "Speed: 0.0ms preprocess, 104.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 99.5ms\n",
      "Speed: 0.0ms preprocess, 99.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 93.9ms\n",
      "Speed: 11.8ms preprocess, 93.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 139.6ms\n",
      "Speed: 0.0ms preprocess, 139.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 90.2ms\n",
      "Speed: 5.6ms preprocess, 90.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 106.1ms\n",
      "Speed: 0.0ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 97.3ms\n",
      "Speed: 2.8ms preprocess, 97.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 98.9ms\n",
      "Speed: 3.2ms preprocess, 98.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 97.8ms\n",
      "Speed: 1.8ms preprocess, 97.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 138.4ms\n",
      "Speed: 28.6ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 1 potted plant, 104.6ms\n",
      "Speed: 3.0ms preprocess, 104.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 110.3ms\n",
      "Speed: 3.0ms preprocess, 110.3ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 122.3ms\n",
      "Speed: 3.0ms preprocess, 122.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 117.6ms\n",
      "Speed: 3.0ms preprocess, 117.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 dogs, 1 chair, 1 potted plant, 151.1ms\n",
      "Speed: 3.0ms preprocess, 151.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 skateboard, 1 chair, 1 potted plant, 88.1ms\n",
      "Speed: 3.0ms preprocess, 88.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 95.7ms\n",
      "Speed: 1.0ms preprocess, 95.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 1 potted plant, 90.8ms\n",
      "Speed: 2.0ms preprocess, 90.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 1 potted plant, 94.3ms\n",
      "Speed: 3.0ms preprocess, 94.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 2 potted plants, 103.4ms\n",
      "Speed: 3.0ms preprocess, 103.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 117.8ms\n",
      "Speed: 0.0ms preprocess, 117.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 133.4ms\n",
      "Speed: 0.0ms preprocess, 133.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 150.1ms\n",
      "Speed: 0.0ms preprocess, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 133.4ms\n",
      "Speed: 16.4ms preprocess, 133.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 166.9ms\n",
      "Speed: 0.0ms preprocess, 166.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 100.9ms\n",
      "Speed: 16.0ms preprocess, 100.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 fire hydrant, 1 dog, 1 chair, 2 potted plants, 95.8ms\n",
      "Speed: 16.7ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 fire hydrant, 1 dog, 1 chair, 2 potted plants, 98.4ms\n",
      "Speed: 0.0ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 1 chair, 2 potted plants, 99.1ms\n",
      "Speed: 3.1ms preprocess, 99.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 fire hydrant, 1 dog, 1 bowl, 2 potted plants, 108.1ms\n",
      "Speed: 3.6ms preprocess, 108.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 chair, 2 potted plants, 97.9ms\n",
      "Speed: 0.0ms preprocess, 97.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 90.9ms\n",
      "Speed: 3.7ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 bowl, 2 potted plants, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 2 potted plants, 125.5ms\n",
      "Speed: 3.5ms preprocess, 125.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 suitcase, 3 potted plants, 120.4ms\n",
      "Speed: 2.9ms preprocess, 120.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 handbag, 1 suitcase, 3 potted plants, 116.6ms\n",
      "Speed: 3.0ms preprocess, 116.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 3 potted plants, 122.5ms\n",
      "Speed: 3.1ms preprocess, 122.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 2 potted plants, 134.4ms\n",
      "Speed: 3.0ms preprocess, 134.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 116.5ms\n",
      "Speed: 3.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 4 potted plants, 126.2ms\n",
      "Speed: 3.0ms preprocess, 126.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 94.5ms\n",
      "Speed: 2.9ms preprocess, 94.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 95.2ms\n",
      "Speed: 3.0ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 123.3ms\n",
      "Speed: 3.0ms preprocess, 123.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 91.1ms\n",
      "Speed: 3.0ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 3 potted plants, 86.3ms\n",
      "Speed: 3.0ms preprocess, 86.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 82.5ms\n",
      "Speed: 3.0ms preprocess, 82.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 85.4ms\n",
      "Speed: 3.0ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 4 potted plants, 85.4ms\n",
      "Speed: 3.0ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 5 potted plants, 101.4ms\n",
      "Speed: 3.0ms preprocess, 101.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 4 potted plants, 90.1ms\n",
      "Speed: 3.3ms preprocess, 90.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 suitcase, 4 potted plants, 120.1ms\n",
      "Speed: 2.5ms preprocess, 120.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 dog, 1 suitcase, 2 potted plants, 118.6ms\n",
      "Speed: 0.0ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 chairs, 3 potted plants, 118.5ms\n",
      "Speed: 4.0ms preprocess, 118.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 chairs, 3 potted plants, 149.2ms\n",
      "Speed: 3.0ms preprocess, 149.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 chairs, 3 potted plants, 125.4ms\n",
      "Speed: 3.0ms preprocess, 125.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 3 potted plants, 115.6ms\n",
      "Speed: 4.1ms preprocess, 115.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 3 potted plants, 90.6ms\n",
      "Speed: 3.6ms preprocess, 90.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 2 potted plants, 83.2ms\n",
      "Speed: 3.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 2 potted plants, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 2 potted plants, 82.1ms\n",
      "Speed: 4.0ms preprocess, 82.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 suitcase, 1 chair, 2 potted plants, 120.2ms\n",
      "Speed: 2.0ms preprocess, 120.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 97.0ms\n",
      "Speed: 7.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 2 potted plants, 86.8ms\n",
      "Speed: 2.5ms preprocess, 86.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 87.7ms\n",
      "Speed: 3.0ms preprocess, 87.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 2 potted plants, 101.2ms\n",
      "Speed: 3.0ms preprocess, 101.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bench, 1 dog, 2 potted plants, 89.1ms\n",
      "Speed: 3.0ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 84.1ms\n",
      "Speed: 3.0ms preprocess, 84.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 3 potted plants, 146.1ms\n",
      "Speed: 3.0ms preprocess, 146.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 127.8ms\n",
      "Speed: 3.5ms preprocess, 127.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 115.6ms\n",
      "Speed: 3.0ms preprocess, 115.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 124.4ms\n",
      "Speed: 3.0ms preprocess, 124.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 chair, 3 potted plants, 121.6ms\n",
      "Speed: 3.1ms preprocess, 121.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 111.6ms\n",
      "Speed: 3.0ms preprocess, 111.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 154.2ms\n",
      "Speed: 3.7ms preprocess, 154.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 4 potted plants, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 113.3ms\n",
      "Speed: 0.0ms preprocess, 113.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 108.3ms\n",
      "Speed: 2.9ms preprocess, 108.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 2 potted plants, 90.7ms\n",
      "Speed: 3.0ms preprocess, 90.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 89.1ms\n",
      "Speed: 3.0ms preprocess, 89.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 2 potted plants, 121.8ms\n",
      "Speed: 2.5ms preprocess, 121.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 5 potted plants, 86.4ms\n",
      "Speed: 3.0ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 86.1ms\n",
      "Speed: 2.0ms preprocess, 86.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 82.1ms\n",
      "Speed: 3.0ms preprocess, 82.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 94.7ms\n",
      "Speed: 0.0ms preprocess, 94.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 84.3ms\n",
      "Speed: 3.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 2 potted plants, 84.6ms\n",
      "Speed: 3.0ms preprocess, 84.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 3 potted plants, 115.8ms\n",
      "Speed: 3.0ms preprocess, 115.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 2 potted plants, 89.0ms\n",
      "Speed: 3.5ms preprocess, 89.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 128.9ms\n",
      "Speed: 0.0ms preprocess, 128.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 114.4ms\n",
      "Speed: 0.0ms preprocess, 114.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 109.6ms\n",
      "Speed: 3.4ms preprocess, 109.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 110.8ms\n",
      "Speed: 2.4ms preprocess, 110.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 2 potted plants, 111.0ms\n",
      "Speed: 2.7ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 146.1ms\n",
      "Speed: 3.0ms preprocess, 146.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 115.7ms\n",
      "Speed: 3.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 94.0ms\n",
      "Speed: 2.0ms preprocess, 94.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 5 potted plants, 92.5ms\n",
      "Speed: 3.6ms preprocess, 92.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 90.8ms\n",
      "Speed: 3.0ms preprocess, 90.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 2 potted plants, 105.9ms\n",
      "Speed: 3.0ms preprocess, 105.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 3 potted plants, 111.6ms\n",
      "Speed: 3.0ms preprocess, 111.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 2 potted plants, 91.8ms\n",
      "Speed: 0.0ms preprocess, 91.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bowl, 1 chair, 2 potted plants, 86.4ms\n",
      "Speed: 3.0ms preprocess, 86.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 suitcase, 1 chair, 86.9ms\n",
      "Speed: 3.0ms preprocess, 86.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 suitcase, 1 chair, 1 potted plant, 89.8ms\n",
      "Speed: 3.0ms preprocess, 89.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 1 potted plant, 134.3ms\n",
      "Speed: 3.0ms preprocess, 134.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 chair, 94.0ms\n",
      "Speed: 3.4ms preprocess, 94.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 113.8ms\n",
      "Speed: 3.5ms preprocess, 113.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bowl, 111.2ms\n",
      "Speed: 3.0ms preprocess, 111.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 112.6ms\n",
      "Speed: 4.0ms preprocess, 112.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 suitcase, 151.2ms\n",
      "Speed: 15.4ms preprocess, 151.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 suitcase, 113.9ms\n",
      "Speed: 4.0ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 115.4ms\n",
      "Speed: 3.4ms preprocess, 115.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 95.6ms\n",
      "Speed: 3.9ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 84.4ms\n",
      "Speed: 3.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 cat, 1 dog, 93.9ms\n",
      "Speed: 3.0ms preprocess, 93.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 1 potted plant, 88.3ms\n",
      "Speed: 3.0ms preprocess, 88.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 cat, 1 dog, 1 potted plant, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 1 potted plant, 84.3ms\n",
      "Speed: 3.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 1 potted plant, 85.3ms\n",
      "Speed: 3.0ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 1 potted plant, 86.5ms\n",
      "Speed: 2.0ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 1 potted plant, 1 tv, 91.7ms\n",
      "Speed: 3.0ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 1 potted plant, 149.6ms\n",
      "Speed: 0.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 dog, 2 potted plants, 141.0ms\n",
      "Speed: 0.0ms preprocess, 141.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 dog, 2 potted plants, 133.2ms\n",
      "Speed: 0.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 dog, 2 potted plants, 116.9ms\n",
      "Speed: 0.0ms preprocess, 116.9ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 potted plant, 125.4ms\n",
      "Speed: 0.0ms preprocess, 125.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 dog, 1 potted plant, 126.0ms\n",
      "Speed: 0.0ms preprocess, 126.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 dog, 1 potted plant, 183.2ms\n",
      "Speed: 0.0ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 potted plant, 100.0ms\n",
      "Speed: 16.7ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cat, 1 potted plant, 149.9ms\n",
      "Speed: 0.7ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 1 potted plant, 166.4ms\n",
      "Speed: 0.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 2 potted plants, 181.6ms\n",
      "Speed: 0.0ms preprocess, 181.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 1 potted plant, 133.4ms\n",
      "Speed: 16.4ms preprocess, 133.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 109.7ms\n",
      "Speed: 16.4ms preprocess, 109.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 potted plants, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 173.0ms\n",
      "Speed: 10.5ms preprocess, 173.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 132.4ms\n",
      "Speed: 0.0ms preprocess, 132.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 130.5ms\n",
      "Speed: 0.0ms preprocess, 130.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 120.9ms\n",
      "Speed: 4.0ms preprocess, 120.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 116.4ms\n",
      "Speed: 1.3ms preprocess, 116.4ms inference, 16.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 149.9ms\n",
      "Speed: 0.0ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 83.4ms\n",
      "Speed: 16.6ms preprocess, 83.4ms inference, 15.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 100.1ms\n",
      "Speed: 0.0ms preprocess, 100.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 100.5ms\n",
      "Speed: 0.0ms preprocess, 100.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 133.8ms\n",
      "Speed: 16.5ms preprocess, 133.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 potted plant, 100.2ms\n",
      "Speed: 0.0ms preprocess, 100.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 115.5ms\n",
      "Speed: 3.1ms preprocess, 115.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 128.8ms\n",
      "Speed: 3.0ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 166.3ms\n",
      "Speed: 0.0ms preprocess, 166.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 1 toilet, 183.2ms\n",
      "Speed: 17.1ms preprocess, 183.2ms inference, 16.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 2 potted plants, 133.0ms\n",
      "Speed: 16.7ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 potted plant, 163.9ms\n",
      "Speed: 0.0ms preprocess, 163.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 1 potted plant, 181.7ms\n",
      "Speed: 3.0ms preprocess, 181.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 1 potted plant, 172.5ms\n",
      "Speed: 3.0ms preprocess, 172.5ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 chairs, 1 potted plant, 131.3ms\n",
      "Speed: 3.0ms preprocess, 131.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 chair, 1 potted plant, 1 toilet, 122.9ms\n",
      "Speed: 2.5ms preprocess, 122.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "JSON results saved to detection_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Path to your video file\n",
    "video_path = r\"C:\\Users\\Lenovo\\Desktop\\SaftyWhatAssessment\\WhatsApp Video 2025-01-10 at 19.49.01_bc3eb6d9.mp4\"\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "object_id = 1  # Initialize unique object ID\n",
    "json_results = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Extract data for JSON\n",
    "    for result in results[0].boxes:\n",
    "        class_name = model.names[int(result.cls)]\n",
    "        bbox = result.xyxy[0].tolist()  # Get bounding box [x1, y1, x2, y2]\n",
    "\n",
    "        # Prepare JSON structure\n",
    "        detection = {\n",
    "            \"object\": class_name,\n",
    "            \"id\": object_id,\n",
    "            \"bbox\": [int(coord) for coord in bbox],\n",
    "            \"subobject\": {}  # Fill in sub-object data later if available\n",
    "        }\n",
    "        json_results.append(detection)\n",
    "        object_id += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Save JSON results to file\n",
    "with open(\"detection_results.json\", \"w\") as f:\n",
    "    json.dump(json_results, f, indent=4)\n",
    "\n",
    "print(\"JSON results saved to detection_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98825254-690d-4f2f-9bbe-405eb2d1212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 1055 detected\n",
      "dog: 423 detected\n",
      "flower pot: 0 detected\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"detection_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Search for specific objects\n",
    "target_objects = [\"person\", \"dog\", \"flower pot\"]\n",
    "found_objects = {obj: 0 for obj in target_objects}\n",
    "\n",
    "for detection in data:\n",
    "    obj_name = detection[\"object\"]\n",
    "    if obj_name in found_objects:\n",
    "        found_objects[obj_name] += 1\n",
    "\n",
    "# Print results\n",
    "for obj, count in found_objects.items():\n",
    "    print(f\"{obj}: {count} detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe55635-8fca-41f9-b80b-dae42e0a1397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: chair\n",
      "Detected: potted plant\n",
      "Detected: toilet\n"
     ]
    }
   ],
   "source": [
    "for result in results[0].boxes:\n",
    "    class_name = model.names[int(result.cls)]\n",
    "    print(f\"Detected: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716c3d80-93ff-4e07-a5a5-5b0dc607c3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'source' is missing. Using 'source=C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets'.\n",
      "\n",
      "image 1/2 C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets\\bus.jpg: 640x480 3 persons, 1 bus, 138.8ms\n",
      "image 2/2 C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets\\zidane.jpg: 384x640 2 persons, 93.6ms\n",
      "Speed: 0.0ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(frame, conf=0.3)  # Lower the threshold to 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2cd86b-f2ea-4464-ae73-8cc9ab93e09d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m: [x1, y1, x2, y2],\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubobject\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}\n\u001b[0;32m      6\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    "  \"object\": \"person\",\n",
    "  \"id\": 1,\n",
    "  \"bbox\": [x1, y1, x2, y2],\n",
    "  \"subobject\": {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18745c84-27a0-4b5f-8555-a0342739b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'person', 'id': 1, 'bbox': [30, 162, 264, 586], 'subobject': {}}\n",
      "{'object': 'person', 'id': 2, 'bbox': [287, 8, 659, 1200], 'subobject': {}}\n",
      "{'object': 'dog', 'id': 3, 'bbox': [219, 579, 503, 907], 'subobject': {}}\n",
      "{'object': 'chair', 'id': 4, 'bbox': [32, 301, 288, 582], 'subobject': {}}\n",
      "{'object': 'person', 'id': 5, 'bbox': [161, 0, 662, 1099], 'subobject': {}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"detection_results.json\", \"r\") as f:\n",
    "    detection_data = json.load(f)\n",
    "\n",
    "# Print the first few entries\n",
    "for entry in detection_data[:5]:  # Display first 5 entries\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7deda62-7b77-4933-aead-5696bcc5c9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
